{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00e832c9-97cf-4393-9f01-2fdf9433def9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "     Month  Hour  DayOfWeek  Holiday  HVACUsage  LightingUsage  Temperature  \\\n",
      "0        7    15          3        0          0              0    31.133301   \n",
      "1        4     3          5        1          1              0    32.160465   \n",
      "2       11    10          5        0          1              1    34.952566   \n",
      "3        8    23          6        1          1              1    19.829930   \n",
      "4        5    22          7        1          1              0    15.807017   \n",
      "..     ...   ...        ...      ...        ...            ...          ...   \n",
      "995      6    23          2        1          0              1    17.465676   \n",
      "996      5     8          6        1          0              0    25.371234   \n",
      "997      6     2          4        1          1              0    19.916949   \n",
      "998      6     9          1        0          1              0    22.162794   \n",
      "999      7    18          6        0          1              0    34.790107   \n",
      "\n",
      "      Humidity  SquareFootage  Occupancy  RenewableEnergy  EnergyConsumption  \n",
      "0    64.215712    4530.000834  88.859928         0.216814         303.051429  \n",
      "1    77.449033    4849.799994  32.907378         0.669611         218.876733  \n",
      "2    37.127828    2495.475963  31.458763         0.970668         254.310332  \n",
      "3    49.106974    1944.486705  51.208858         0.175715         193.533647  \n",
      "4    57.736590    2867.423060  94.069019         0.597117         245.488246  \n",
      "..         ...            ...        ...              ...                ...  \n",
      "995  42.199765    3578.940838   6.560076         0.499036         266.144303  \n",
      "996  78.336711    4470.985361  69.061531         0.931535         266.303931  \n",
      "997  77.906906    1415.799987  57.240773         0.583333         371.691724  \n",
      "998  42.381582    4430.125030  40.451952         0.538384         347.577869  \n",
      "999  47.402598     768.930234  36.361145         0.454483         215.325045  \n",
      "\n",
      "[1000 rows x 12 columns]\n",
      "Removed 6 outliers.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexe\\AppData\\Local\\Temp\\ipykernel_12172\\3482620669.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_reduced = df.replace({'Monday': 1, 'Tuesday': 2, 'Wednesday': 3,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 78832.3906 - mae: 274.7935 - val_loss: 12078.9609 - val_mae: 97.6144\n",
      "Epoch 2/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5983.1860 - mae: 63.4519 - val_loss: 2982.1260 - val_mae: 43.0983\n",
      "Epoch 3/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3608.1733 - mae: 47.1467 - val_loss: 2826.0120 - val_mae: 42.3877\n",
      "Epoch 4/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3023.7046 - mae: 43.8165 - val_loss: 2814.9319 - val_mae: 42.3688\n",
      "Epoch 5/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3118.9343 - mae: 43.5054 - val_loss: 2744.5833 - val_mae: 42.1096\n",
      "Epoch 6/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3111.1245 - mae: 44.2365 - val_loss: 2706.9570 - val_mae: 42.1363\n",
      "Epoch 7/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2982.8406 - mae: 43.6529 - val_loss: 2759.5076 - val_mae: 42.6746\n",
      "Epoch 8/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2760.7083 - mae: 41.4194 - val_loss: 2679.4792 - val_mae: 41.6516\n",
      "Epoch 9/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2933.2803 - mae: 42.6553 - val_loss: 2680.1865 - val_mae: 42.0070\n",
      "Epoch 10/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2672.6821 - mae: 40.6562 - val_loss: 2635.4089 - val_mae: 41.4916\n",
      "Epoch 11/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2808.2893 - mae: 42.5546 - val_loss: 2560.6372 - val_mae: 40.9449\n",
      "Epoch 12/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2545.2644 - mae: 39.6812 - val_loss: 2643.5452 - val_mae: 41.4941\n",
      "Epoch 13/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2698.5356 - mae: 41.0289 - val_loss: 2648.2283 - val_mae: 41.0223\n",
      "Epoch 14/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2589.1077 - mae: 40.2037 - val_loss: 2577.6223 - val_mae: 41.5682\n",
      "Epoch 15/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2418.4639 - mae: 38.9114 - val_loss: 2600.8396 - val_mae: 40.9635\n",
      "Epoch 16/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2536.2820 - mae: 39.7134 - val_loss: 2517.4377 - val_mae: 40.7894\n",
      "Epoch 17/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2516.3733 - mae: 39.5818 - val_loss: 2610.0278 - val_mae: 41.1622\n",
      "Epoch 18/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2444.0142 - mae: 39.3028 - val_loss: 2533.4009 - val_mae: 40.5311\n",
      "Epoch 19/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2682.8530 - mae: 40.7601 - val_loss: 2577.2402 - val_mae: 41.3581\n",
      "Epoch 20/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2274.4019 - mae: 37.2051 - val_loss: 2598.7888 - val_mae: 40.8776\n",
      "Epoch 21/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2503.3042 - mae: 39.8761 - val_loss: 2539.4175 - val_mae: 40.8769\n",
      "Epoch 22/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2429.7307 - mae: 38.9856 - val_loss: 2605.3259 - val_mae: 41.0714\n",
      "Epoch 23/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2416.9758 - mae: 38.7735 - val_loss: 2505.3057 - val_mae: 41.0795\n",
      "Epoch 24/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2569.7698 - mae: 40.0627 - val_loss: 2524.5269 - val_mae: 40.7933\n",
      "Epoch 25/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2271.6211 - mae: 37.6189 - val_loss: 2530.8433 - val_mae: 40.6114\n",
      "Epoch 26/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2511.2117 - mae: 39.6933 - val_loss: 2525.2512 - val_mae: 40.9561\n",
      "Epoch 27/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2359.3640 - mae: 38.7314 - val_loss: 2509.4067 - val_mae: 40.9248\n",
      "Epoch 28/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2465.7473 - mae: 39.1311 - val_loss: 2476.3354 - val_mae: 39.9644\n",
      "Epoch 29/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2357.0305 - mae: 37.7507 - val_loss: 2537.7483 - val_mae: 41.2225\n",
      "Epoch 30/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2425.3027 - mae: 39.0877 - val_loss: 2463.1226 - val_mae: 40.4030\n",
      "Epoch 31/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2379.5520 - mae: 39.0665 - val_loss: 2466.3816 - val_mae: 40.2537\n",
      "Epoch 32/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2241.9556 - mae: 38.1251 - val_loss: 2495.8352 - val_mae: 40.1586\n",
      "Epoch 33/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2349.4158 - mae: 38.8463 - val_loss: 2474.3818 - val_mae: 40.5196\n",
      "Epoch 34/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2474.7527 - mae: 40.0330 - val_loss: 2492.7771 - val_mae: 40.4186\n",
      "Epoch 35/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2334.2004 - mae: 38.2939 - val_loss: 2528.9834 - val_mae: 40.2132\n",
      "Epoch 36/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2399.9377 - mae: 38.7936 - val_loss: 2486.9312 - val_mae: 40.1664\n",
      "Epoch 37/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2348.2859 - mae: 38.6818 - val_loss: 2569.0300 - val_mae: 41.6253\n",
      "Epoch 38/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2361.4668 - mae: 39.1197 - val_loss: 2536.9937 - val_mae: 41.1025\n",
      "Epoch 39/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2195.0605 - mae: 36.7960 - val_loss: 2526.6768 - val_mae: 40.0488\n",
      "Epoch 40/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2079.8464 - mae: 36.4968 - val_loss: 2553.1218 - val_mae: 39.9813\n",
      "Epoch 41/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2407.8984 - mae: 38.8541 - val_loss: 2533.2070 - val_mae: 40.4339\n",
      "Epoch 42/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2241.0664 - mae: 37.5389 - val_loss: 2636.3376 - val_mae: 40.6042\n",
      "Epoch 43/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2235.8511 - mae: 37.2381 - val_loss: 2471.2500 - val_mae: 40.4408\n",
      "Epoch 44/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2110.0112 - mae: 35.7023 - val_loss: 2485.3918 - val_mae: 40.9457\n",
      "Epoch 45/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2138.1741 - mae: 36.8055 - val_loss: 2521.7866 - val_mae: 40.6137\n",
      "Epoch 46/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2226.2854 - mae: 37.3339 - val_loss: 2501.8418 - val_mae: 40.2209\n",
      "Epoch 47/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2135.9565 - mae: 36.4639 - val_loss: 2477.8564 - val_mae: 40.3013\n",
      "Epoch 48/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2164.5522 - mae: 36.3845 - val_loss: 2440.7957 - val_mae: 39.7698\n",
      "Epoch 49/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2154.7837 - mae: 36.5792 - val_loss: 2497.3127 - val_mae: 40.3715\n",
      "Epoch 50/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2295.0073 - mae: 37.8853 - val_loss: 2565.1306 - val_mae: 40.9987\n",
      "Test Loss (MSE): 2565.1306\n",
      "Test Mean Absolute Error (MAE): 40.9987\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Predictions for EnergyConsumption:\n",
      "[621.0872  550.7764  588.51514 598.07684 578.5106  606.09894 534.4811\n",
      " 552.77905 545.92804 582.8187  515.1009  548.9786  538.7876  680.8918\n",
      " 554.7402  573.19366 606.7349  549.1938  546.92206 589.49194 562.7456\n",
      " 557.15137 532.30225 533.3915  539.07697 609.43463 666.62634 521.66614\n",
      " 526.2792  543.04834 611.5173  503.06177 529.2491  534.07825 581.958\n",
      " 582.0965  549.6765  507.79865 537.9385  568.4849  536.0841  574.11035\n",
      " 521.7417  541.9331  517.4038  574.92554 570.0315  620.6458  529.95966\n",
      " 545.7043 ]\n",
      "Manual MAE: 40.9987\n",
      "14.137231573265833 per cent\n",
      "1122.328958404541\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"Energy_Consumption_Dataset.csv\"  # Replace with your dataset file path\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}\")\n",
    "   # exit()\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "df_reduced = df.replace({'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, \n",
    "                         'Thursday': 4, 'Friday': 5, 'Saturday': 6, 'Sunday': 7, \n",
    "                         'Yes': 1, 'No': 0, 'On': 0, 'Off': 1}).infer_objects(copy=False)\n",
    "\n",
    "# Step 2: Verify Data and remove outliers\n",
    "print(df_reduced)\n",
    "\n",
    "# Use IQR to detect and remove outliers\n",
    "Q1 = df_reduced.quantile(0.25)\n",
    "Q3 = df_reduced.quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Filter the dataset\n",
    "df_cleaned = df_reduced[~((df_reduced < (Q1 - 1.5 * IQR)) | (df_reduced > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "print(f\"Removed {len(df_reduced) - len(df_cleaned)} outliers.\")\n",
    "\n",
    "# Step 3: Model Processing\n",
    "\n",
    "df_reduced = df_cleaned\n",
    "\n",
    "# Define input features (X) and target variable (y)\n",
    "input_data = df_reduced.drop(columns=[\"EnergyConsumption\"])  # Features\n",
    "output_data = df_reduced[\"EnergyConsumption\"]  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "input_data_train, input_data_test, output_data_train, output_data_test = train_test_split(input_data, output_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the numerical features for better performance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "input_data_train = scaler.fit_transform(input_data_train)\n",
    "input_data_test = scaler.transform(input_data_test)\n",
    "\n",
    "# Step 2: Build the TensorFlow Model\n",
    "model = Sequential([\n",
    "    Dense(400, input_dim=input_data_train.shape[1], activation=\"relu\"),  # Input layer with 4 neurons\n",
    "    Dense(1280, activation=\"relu\"),                             # Hidden layer with 128 neurons\n",
    "    Dense(1, activation=\"linear\")                              # Output layer (1 neuron for regression)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])  # Loss: Mean Squared Error, Metric: Mean Absolute Error\n",
    "\n",
    "# Step 3: Train the Model\n",
    "history = model.fit(input_data_train, output_data_train, epochs=50, batch_size=16, validation_data=(input_data_test, output_data_test), verbose=1)\n",
    "\n",
    "# Step 4: Evaluate the Model\n",
    "loss, mae = model.evaluate(input_data_test, output_data_test, verbose=0)\n",
    "\n",
    "print(f\"Test Loss (MSE): {loss:.4f}\")\n",
    "print(f\"Test Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "# Step 5: Make Predictions\n",
    "predictions = model.predict(input_data_test)\n",
    "\n",
    "# Flatten the predictions to make them 1D\n",
    "predictions = predictions.flatten()\n",
    "\n",
    "# Print first 50 predictions\n",
    "print(\"Predictions for EnergyConsumption:\")\n",
    "print(predictions[:50]*2.5*85.0*365.0*24.0*1.0E-6) # Terawatt \n",
    "\n",
    "# Calculate Mean Absolute Error manually (for comparison)\n",
    "mae_manual = mean_absolute_error(output_data_test, predictions)\n",
    "print(f\"Manual MAE: {mae_manual:.4f}\")\n",
    "\n",
    "mre = np.mean(np.abs((output_data_test - predictions) / output_data_test))\n",
    "print(mre*100.0, 'per cent')\n",
    "\n",
    "print(predictions.mean()*2.5*85.0*365.00*24.0*1.0E-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d0cff1-f9eb-46e2-a67b-e435cb58dffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
